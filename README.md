
 <div align='center' > 
  <h2> ACM Multimedia </h2>
 </div>

 <div align='center' style = "vertical-align:middle"> 
  <h2> <img src="https://www.acmmm2023.org/wp-content/uploads/2022/12/cropped-cropped-sigmmlogo-1.gif" margn-right="20px" ><a href="https://www.acmmm2023.org/"> ACM MM 2023 </a><a href="https://www.acmmm2023.org/">(https://www.acmmm2023.org/)</a> </h2>
 </div>
 
 <div align='center' > 
  <h2> Workshop on </h2>
  <h2> UAVs in Multimedia: Capturing the World from a New Perspective
</h2>
 </div>


The accept papers will be published at ACM Multimedia Workshop (top 50%), and go through the same peer review process as the regular papers. Some authors will be invited to do a oral presentation. 

## Abstract:
Unmanned Aerial Vehicles (UAVs), also known as drones, have become increasingly popular in recent years due to their ability to capture high-quality multimedia data from the sky. With the rise of multimedia applications, such as aerial photography, cinematography, and mapping, UAVs have emerged as a powerful tool for gathering rich and diverse multimedia content. This workshop aims to bring together researchers, practitioners, and enthusiasts interested in UAV multimedia to explore the latest advancements, challenges, and opportunities in this exciting field. The workshop will cover various topics related to UAV multimedia, including aerial image and video processing, machine learning for UAV data analysis, UAV swarm technology, and UAV-based multimedia applications. In the context of the ACM Multimedia conference, this workshop is highly relevant as multimedia data from UAVs is becoming an increasingly important source of content for many multimedia applications. The workshop will provide a platform for researchers to share their work and discuss potential collaborations, as well as an opportunity for practitioners to learn about the latest developments in UAV multimedia technology.
Overall, this workshop will provide a unique opportunity to explore the exciting and rapidly evolving field of UAV multimedia and its potential impact on the wider multimedia community.


**The list of possible topics includes, but is not limited to:**

*  Video-based UAV Navigation
    + Satellite-guided & Ground-guided Navigation
    + Path Planning and Obstacle Avoidance
    + Visual SLAM (Simultaneous Localization and Mapping)
    + Sensor Fusion and Reinforcement Learning for Navigation
* UAV Swarm Coordination
    + Multiple Platform Collaboration
    + Multi-agent Cooperation and Communication
    + Decentralized Control and Optimization
    + Distributed Perception and Mapping
* UAV-based Object Detection and Tracking
    + Aerial-view Object Detection, Tracking and Re-identification
    + Aerial-view Action Recognition
* UAV-based Sensing and Mapping
    + 3D Mapping and Reconstruction
    + Remote Sensing and Image Analysis
    + Disaster Response and Relief
* UAV-based Delivery and Transportation
    + Package Delivery and Logistics
    + Safety and Regulations for UAV-based Transportation

**Reference:**

[1] Kendall A, Gal Y. What uncertainties do we need in bayesian deep learning for computer vision? NeurIPS, 2017.

[2] Zheng Z, Yang Y. Rectifying pseudo label learning via uncertainty estimation for domain adaptive semantic segmentation. IJCV, 2021. 

[3] Four Principles of Explainable Artificial Intelligence (https://nvlpubs.nist.gov/nistpubs/ir/2021/NIST.IR.8312.pdf)

[4] Zheng, Z., Ruan, T., Wei, Y., Yang, Y., & Mei, T. VehicleNet: Learning robust visual representation for vehicle re-identification. TMM, 2020.

**Tips:**
- For privacy protection, please blur faces in the published materials (such as paper, video, poster, etc.) 
- For social good, please do not contain any misleading words, such as ``surveillance`` and  ``secret``.


## Challenge
We also provide a challenging cross-view geo-localization dataset, called University160k, and the workshop audience may consider to participate the competition. The motivation is to simulate the real- world geo-localization scenario that we usually face an extremely large satellite-view pool. In particular, University160k extends the current University-1652 dataset with extra 167,486 satellite- view gallery distractors. We will release University160k on our website, and make a public leader board. These distractor satellite- view images have a size of 1024 × 1024 and are obtained by cutting orthophoto images of real urban and surrounding areas. The larger image size ensures higher image clarity, while the wider framing range allows the images to contain more diverse scenes, such as buildings, city roads, trees, fields, and more (see Figure 3). In our primary evaluation, the distractor is challenging and make the com- petitive baseline model, LPN, decrease the Recall@1 accuracy from 75.93% to 64.85% and the value of AP from 79.14% to 67.69% in the Drone → Satellite task (Please see Table 2). We hope more audiences can be involved to solve this challenge, and may also consider the efficiency problem against a large candidate pool.

Check challenge details at https://zdzheng.xyz/files/MM23-Workshop.pdf

## Important Dates

**Submission of papers:**

* New Regular Paper Submission deadline: TBD [11:59 p.m. PST]
* Paper acceptance notification: August 6, 2023

## Organizing Team

| <img src="./picture/1.png" width="160"> |<img src="https://shiyujiao.github.io/images/YujiaoShiCircle.jpg" width="160"> |<img src="" width="160"> |
| :-: | :-: | :-: |
|  [Zhedong Zheng](zdzheng.xyz), National University of Singapore, Singapore | [Yujiao Shi](https://shiyujiao.github.io/), Australian National University, Australia | [Tingyu Wang](https://scholar.google.com/citations?user=wv3H-F4AAAAJ), Hangzhou Dianzi University, China |
| <img src="https://istd.sutd.edu.sg/files/xistd-faculty-liu-jun-2021.jpg.pagespeed.ic.kj4jHLG_to.webp" width="160"> |  <img src="https://jwfangit.github.io/img/pic.jpg" width="160"> | <img src="https://weiyc.github.io/images/people/wyc.jpg" width="160"> | 
|  [Jun Liu](https://istd.sutd.edu.sg/people/faculty/liu-jun), Singapore University of Technology and Design, Singapore |  [Jianwu Fang](www.lotvs.net), Chang'an University, China |  [Yunchao Wei](https://weiyc.github.io), Beijing Jiaotong University, China | 
<img src="./picture/5.png" width="160"> |
[Tat-Seng Chua](https://www.chuatatseng.com), National University of Singapore, Singapore |


## Conference and Journal Papers

All papers presented at ACMMM 2023 will be included in ACM proceeding. All papers submitted to this special session will go through the same review process as the regular papers submitted to the main conference to ensure that the contributions are of high quality. 
